{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CelebA + Adversarial Robustness Toolbox Demo\n",
        "\n",
        "This notebook:\n",
        "1. Installs necessary packages.\n",
        "2. Loads the CelebA dataset from Hugging Face.\n",
        "3. Trains a simple CNN.\n",
        "4. Demonstrates a FGSM attack.\n",
        "5. Shows an example of face obfuscation with OpenCV.\n",
        "\n",
        "Please ensure you have **accepted the license** for `celeba` on Hugging Face and that you're **logged in** with a valid Hugging Face token.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%%capture\n",
        "# Install packages\n",
        "!pip install --upgrade pip\n",
        "!pip install --upgrade datasets huggingface_hub\n",
        "!pip install adversarial-robustness-toolbox opencv-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (Optional) Hugging Face Authentication\n",
        "If CelebA is public and you have accepted the terms, you *might* be able to skip. If you see `DatasetNotFoundError`, come back here.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# (Optional) authenticate with Hugging Face\n",
        "from huggingface_hub import notebook_login\n",
        "# notebook_login()  # Uncomment if needed; paste your token"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "from art.estimators.classification import TensorFlowV2Classifier\n",
        "from art.attacks.evasion import FastGradientMethod\n",
        "from art.utils import load_dataset\n",
        "\n",
        "from datasets import load_dataset\n",
        "from PIL import Image\n",
        "\n",
        "matplotlib.rcParams.update({\"font.size\": 14})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the CelebA dataset\n",
        "We use `.with_format('image')` so that each row's `\"image\"` key is a PIL image (instead of a string or array)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "celeba_all = load_dataset(\"celeba\", \"original\")  # Requires having accepted the license\n",
        "celeba_all = celeba_all.with_format(\"image\")\n",
        "\n",
        "print(celeba_all)\n",
        "print(\"\\nSample record:\", celeba_all[\"train\"][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a small subset for demonstration\n",
        "We’ll take 2k images for training, 500 images for test to keep it short. Adjust as needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_data = celeba_all[\"train\"].select(range(2000))\n",
        "test_data = celeba_all[\"test\"].select(range(500))\n",
        "\n",
        "print(train_data[0].keys())  # should have 'image', 'attributes', etc.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocess data (resize to 28×28, grayscale, pick a 'Male' label)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def transform_celebA_entry(entry, image_size=(28, 28)):\n",
        "    \"\"\"\n",
        "    - entry[\"image\"]: a PIL image.\n",
        "    - entry[\"attributes\"]: dict with many attributes, including 'Male'.\n",
        "    \"\"\"\n",
        "    # Convert to grayscale, resize\n",
        "    img = entry[\"image\"].convert(\"L\").resize(image_size)\n",
        "    arr = np.array(img, dtype=np.float32) / 255.0\n",
        "    # 'Male' is True/False in attributes\n",
        "    is_male = bool(entry[\"attributes\"][\"Male\"])\n",
        "    one_hot = np.zeros(2, dtype=np.float32)\n",
        "    if is_male:\n",
        "        one_hot[1] = 1.0  # male\n",
        "    else:\n",
        "        one_hot[0] = 1.0  # female\n",
        "    return arr, one_hot\n",
        "\n",
        "train_images = []\n",
        "train_labels = []\n",
        "for i in range(len(train_data)):\n",
        "    entry = train_data[i]\n",
        "    arr, label = transform_celebA_entry(entry)\n",
        "    train_images.append(arr)\n",
        "    train_labels.append(label)\n",
        "\n",
        "test_images = []\n",
        "test_labels = []\n",
        "for i in range(len(test_data)):\n",
        "    entry = test_data[i]\n",
        "    arr, label = transform_celebA_entry(entry)\n",
        "    test_images.append(arr)\n",
        "    test_labels.append(label)\n",
        "\n",
        "train_images = np.array(train_images).reshape((-1, 28, 28, 1))\n",
        "train_labels = np.array(train_labels)\n",
        "test_images = np.array(test_images).reshape((-1, 28, 28, 1))\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "print(\"Train images:\", train_images.shape)\n",
        "print(\"Train labels:\", train_labels.shape)\n",
        "print(\"Test images:\\t\", test_images.shape)\n",
        "print(\"Test labels:\\t\", test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train a simple CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def create_model():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
        "        tf.keras.layers.MaxPool2D(2,2),\n",
        "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        tf.keras.layers.MaxPool2D(2,2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(2, activation='softmax')\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "model.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=3,\n",
        "    batch_size=64\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FGSM Attack with ART"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "classifier = TensorFlowV2Classifier(\n",
        "    clip_values=(0, 1),\n",
        "    model=model,\n",
        "    nb_classes=2,\n",
        "    input_shape=(28,28,1),\n",
        "    loss_object=loss_object,\n",
        ")\n",
        "\n",
        "fgsm = FastGradientMethod(estimator=classifier, eps=0.3)\n",
        "test_images_adv = fgsm.generate(x=test_images)\n",
        "\n",
        "score_clean = model.evaluate(test_images, test_labels, verbose=0)\n",
        "score_adv   = model.evaluate(test_images_adv, test_labels, verbose=0)\n",
        "\n",
        "print(\"Clean test accuracy:      {:.2f}%\".format(score_clean[1]*100))\n",
        "print(\"Adversarial test accuracy: {:.2f}%\".format(score_adv[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Face Obfuscation Demo\n",
        "We can optionally do face obfuscation with Haar Cascade. We'll pick random face patches from the CelebA train subset. Just a minimal example!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Download Haar Cascade for frontal faces\n",
        "!wget -q https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "def random_face_from_celeba():\n",
        "    random_idx = random.randint(0, len(train_data)-1)\n",
        "    # This is a PIL image in RGB\n",
        "    return train_data[random_idx]['image'].convert('RGB')\n",
        "\n",
        "def obfuscate_face(image_path):\n",
        "    \"\"\"Detect faces, replace with random CelebA face patches.\"\"\"\n",
        "    img_bgr = cv2.imread(image_path)\n",
        "    if img_bgr is None:\n",
        "        print(\"Could not read image.\")\n",
        "        return None\n",
        "\n",
        "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        # get random celeb face\n",
        "        celeb_pil = random_face_from_celeba()\n",
        "        # resize to face bounding box\n",
        "        celeb_pil = celeb_pil.resize((w,h))\n",
        "        celeb_np = np.array(celeb_pil)  # shape (h, w, 3)\n",
        "        # Overwrite region in original image\n",
        "        # Note: celeb_np is RGB, but img_bgr is BGR\n",
        "        img_bgr[y:y+h, x:x+w] = celeb_np[:, :, ::-1]\n",
        "\n",
        "    return img_bgr\n",
        "\n",
        "print(\"Face obfuscation ready.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Upload an image (in Colab) and show obfuscation result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # pick an image with a face\n",
        "if uploaded:\n",
        "    up_name = list(uploaded.keys())[0]\n",
        "    result_bgr = obfuscate_face(up_name)\n",
        "    if result_bgr is not None:\n",
        "        result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)\n",
        "        plt.figure(figsize=(6,6))\n",
        "        plt.imshow(result_rgb)\n",
        "        plt.title(\"Obfuscated face w/ random CelebA patch\")\n",
        "        plt.axis('off')\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "mimetype": "text/x-python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
